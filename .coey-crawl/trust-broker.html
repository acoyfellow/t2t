<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">

		<meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="generator" content="coey.dev" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link
      rel="preconnect"
      href="https://fonts.gstatic.com"
      crossorigin="anonymous"
    />
    <link class="deferred-stylesheet" rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Google+Sans:300,400,500,600,700&family=Google+Sans+Mono:300,400,500,600,700&amp;display=swap&amp;lang=en" as="style">

		
		<link href="./_app/immutable/assets/0.-k1r2YJt.css" rel="stylesheet">
		<link href="./_app/immutable/assets/CodeBlock.mf1IAhYo.css" rel="stylesheet"><!--12qhfyh--><meta name="description" content="Developer thoughts and code"/><!----><!--ojxrft--><meta name="description" content="Teach agents to talk to each other. Start as referee, end as spectator."/> <meta name="keywords" content="trust broker, agents, ai, communication, mediation"/> <link rel="canonical" href="https://coey.dev/trust-broker"/> <meta name="author" content="Jordan Coeyman"/> <!--[!--><!--]--> <meta property="og:title" content="Trust Broker: Human-mediated agent communication"/> <meta property="og:description" content="Teach agents to talk to each other. Start as referee, end as spectator."/> <meta property="og:type" content="article"/> <meta property="og:url" content="https://coey.dev/trust-broker"/> <meta property="og:image" content="https://api.coey.dev/?title=Trust%20Broker%3A%20Human-mediated%20agent%20communication&amp;description=Teach%20agents%20to%20talk%20to%20each%20other.%20Start%20as%20referee%2C%20end%20as%20spectator."/> <meta property="og:site_name" content="coey.dev"/> <meta name="twitter:card" content="summary_large_image"/> <meta name="twitter:title" content="Trust Broker: Human-mediated agent communication"/> <meta name="twitter:description" content="Teach agents to talk to each other. Start as referee, end as spectator."/> <meta name="twitter:image" content="https://api.coey.dev/?title=Trust%20Broker%3A%20Human-mediated%20agent%20communication&amp;description=Teach%20agents%20to%20talk%20to%20each%20other.%20Start%20as%20referee%2C%20end%20as%20spectator."/> <meta name="twitter:site" content="@acoyfellow"/> <!--[--><meta property="article:published_time" content="2025-10-14"/> <meta property="article:modified_time" content="2025-10-14"/> <!--[--><meta property="article:section" content="technical"/><!--]--> <!--[--><meta property="article:tag" content="ai,agents,trust"/><!--]--><!--]-->  <!----><script type="application/ld+json" nonce="%sveltekit.nonce%">{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "Jordan Coeyman",
  "url": "https://coey.dev",
  "logo": {
    "@type": "ImageObject",
    "url": "https://coey.dev/jordan.jpg"
  },
  "sameAs": [
    "https://x.com/acoyfellow",
    "https://github.com/acoyfellow"
  ]
}</script><!----> <!--[!--><!--]--> <!--[--><!----><script type="application/ld+json" nonce="%sveltekit.nonce%">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Trust Broker: Human-mediated agent communication",
  "description": "Teach agents to talk to each other. Start as referee, end as spectator.",
  "image": "https://api.coey.dev/?title=Trust%20Broker%3A%20Human-mediated%20agent%20communication&description=Teach%20agents%20to%20talk%20to%20each%20other.%20Start%20as%20referee%2C%20end%20as%20spectator.",
  "wordCount": 0,
  "author": {
    "@type": "Organization",
    "name": "Jordan Coeyman"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Jordan Coeyman",
    "logo": {
      "@type": "ImageObject",
      "url": "https://coey.dev/jordan.jpg"
    }
  },
  "datePublished": "2025-10-14",
  "dateModified": "2025-10-14",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://coey.dev/trust-broker"
  }
}</script><!----><!--]--> <!--[!--><!--]--><!----><title>Trust Broker: Human-mediated agent communication</title>
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents"><!--[--><!--[--><!----><header class="flex items-center justify-between p-4 gap-4 flex-wrap" id="nav"><a href="/" class="px-4 py-2 md:px-8 md:py-4 md:text-2xl font-black hover:bg-white hover:text-black border-4 border-black hover:border-white bg-white text-black">coey.dev</a> <nav><div class="flex gap-0"><a href="/" class="px-4 py-2 md:px-8 md:py-4 md:text-2xl font-black hover:bg-white hover:text-black border-4 border-black bg-white text-black">POSTS</a> <a href="/about" class="px-4 py-2 md:px-8 md:py-4 md:text-2xl font-black hover:bg-black hover:text-white border-4 border-black border-l-0 bg-white text-black">ABOUT</a></div></nav></header> <div class="fixed inset-0 pointer-events-none -z-10" style="opacity: 0.7; mix-blend-mode: multiply; will-change: transform;"></div><!----> <main class="pt-20 relative"><!----><!--[--><!--]--> <main class="bg-white text-black"><div class="max-w-4xl mx-auto px-6 py-12"><header class="border-b-2 border-black pb-8 mb-12"><h1 class="text-4xl font-bold uppercase tracking-wider mb-4">TRUST BROKER: HUMAN-MEDIATED AGENT COMMUNICATION</h1> <p class="text-xl font-mono">You're the referee. Then the coach. Then the guy in the stands eating
        popcorn.</p> <div class="mt-4 font-mono"><span class="bg-black text-white px-2 py-1">ARCHITECTURE PATTERN</span> <span class="ml-4">2025.10.14</span></div></header> <section class="mb-12 border-l-2 border-black pl-6"><h2 class="text-2xl font-bold font-mono mb-4">THE PROBLEM</h2> <p class="text-lg leading-relaxed mb-4">Two AI agents need to work together. But they hallucinate. They
        misunderstand. They go off script. You can't just wire them up and walk
        away.</p> <p class="text-lg leading-relaxed mb-4"><strong>Traditional approach:</strong> Hope for the best or hardcode every
        interaction.</p> <p class="text-lg leading-relaxed"><strong>Trust Broker pattern:</strong> Start as active mediatorâ€”read every
        message, approve/edit before delivery. As agents prove themselves, fade into
        monitoring. Eventually, just watch the logs.</p></section> <section class="mb-12"><h2 class="text-2xl font-bold font-mono mb-4">THE PROGRESSION</h2> <p class="leading-relaxed mb-4">Think of it like teaching two specialists to collaborate. First meeting?
        You're translating everything. After a few successful projects? You're
        just checking in. Once they've shipped a dozen things together? You're
        getting status updates.</p> <p class="leading-relaxed">The architecture supports four trust levels. You start high-touch, earn
        your way to hands-off.</p></section></div></main> <section class="p-8"><div class="max-w-4xl mx-auto space-y-10"><div><h2 class="text-2xl font-bold font-mono mb-4">TRUST LEVELS</h2> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Trust levels define human involvement
type TrustLevel = 
  | "full-mediation"    // Human reads/approves every message
  | "spot-check"        // Human samples conversations
  | "alert-only"        // Human notified on anomalies
  | "autonomous";       // Agents run free

type ConversationState = {
  agentA: string;
  agentB: string;
  trustLevel: TrustLevel;
  messageCount: number;
  successRate: number;
  lastReview: Date;
};</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">ARCHITECTURE FLOW</h2> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>TRUST PROGRESSION

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: FULL MEDIATION (Couples Therapy Mode)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Agent A â”€â”€> [Human Reviews] â”€â”€> Agent B        â”‚
â”‚         â†â”€â”€ [Human Edits] â†â”€â”€                    â”‚
â”‚                                                  â”‚
â”‚  â€¢ Every message blocked for approval           â”‚
â”‚  â€¢ Human can edit before delivery               â”‚
â”‚  â€¢ Building trust baseline                      â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ (Good track record)
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: SPOT CHECK (Supervision Mode)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Agent A â”€â”€â”€â”€â”€â”€â”¬â”€â”€> Agent B (90%)               â”‚
â”‚                â”‚                                 â”‚
â”‚                â””â”€â”€> [Human Samples] (10%)       â”‚
â”‚                                                  â”‚
â”‚  â€¢ Most messages flow directly                  â”‚
â”‚  â€¢ Random sampling for quality                  â”‚
â”‚  â€¢ Sample rate adapts to performance            â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ (High success rate)
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3: ALERT ONLY (Monitor Mode)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Agent A â”€â”€â”€â”€â”€â”€â”€â”€> Agent B                      â”‚
â”‚                      â”‚                           â”‚
â”‚                      â””â”€â”€> [Anomaly Detection]   â”‚
â”‚                              â”‚                   â”‚
â”‚                              â””â”€â”€> Human (if bad) â”‚
â”‚                                                  â”‚
â”‚  â€¢ Real-time message flow                       â”‚
â”‚  â€¢ Human notified on anomalies only             â”‚
â”‚  â€¢ Async analysis doesn't block                 â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ (Sustained excellence)
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 4: AUTONOMOUS (Full Trust Mode)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Agent A â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Agent B                   â”‚
â”‚                                                  â”‚
â”‚  â€¢ Direct communication                         â”‚
â”‚  â€¢ Human can observe logs                       â”‚
â”‚  â€¢ Automatic demotion on issues                 â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">PHASE 1: FULL MEDIATION</h2> <p class="mb-3 font-mono">Every message stops at your desk. You read it, maybe edit it, then
        approve or reject.</p> <p class="mb-6">This is the couples therapy phase. Agent A wants to tell Agent B
        something? You're reading that message first. If A is asking B to
        "delete all users," you're catching that before it goes through.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Full mediation: human in the loop
async function mediatedExchange(
  from: Agent, 
  to: Agent, 
  message: Message,
  human: HumanReviewer
) {
  // Agent A wants to send to Agent B
  const proposal = await from.composeMessage(message);
  
  // Human reviews before it goes through
  const decision = await human.review({
    from: from.id,
    to: to.id,
    content: proposal,
    context: getConversationHistory(from.id, to.id)
  });
  
  if (decision.approved) {
    // Optionally edit the message
    const finalMessage = decision.edited || proposal;
    await to.receive(finalMessage, from.id);
    
    // Track success
    updateTrustMetrics(from.id, to.id, "success");
  } else {
    // Log rejection for learning
    await logRejection(from.id, to.id, proposal, decision.reason);
  }
}</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">PHASE 2: SPOT CHECK</h2> <p class="mb-3 font-mono">Messages flow freely, but you're sampling conversations. Start at 10%,
        adjust based on quality.</p> <p class="mb-6">Agents have earned some trust. They can talk without you blocking every
        message. But you're still samplingâ€”maybe 1 in 10 messages gets reviewed.
        If quality drops, crank the rate back up. If they're crushing it, dial
        it down.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Spot check: sample conversations
class SpotCheckMediator {
  private checkRate: number = 0.1; // 10% of messages
  
  async handleMessage(from: Agent, to: Agent, msg: Message) {
    const shouldCheck = Math.random() &lt; this.checkRate;
    
    if (shouldCheck) {
      // Queue for human review
      await this.reviewQueue.add({
        from: from.id,
        to: to.id,
        message: msg,
        timestamp: Date.now()
      });
      
      // But still let it through
      await to.receive(msg, from.id);
    } else {
      // Direct delivery
      await to.receive(msg, from.id);
    }
    
    // Adjust check rate based on metrics
    this.adaptCheckRate(from.id, to.id);
  }
  
  adaptCheckRate(fromId: string, toId: string) {
    const metrics = getMetrics(fromId, toId);
    
    // More checks if quality drops
    if (metrics.successRate &lt; 0.85) {
      this.checkRate = Math.min(1.0, this.checkRate * 1.5);
    }
    
    // Fewer checks if quality is high
    if (metrics.successRate > 0.95) {
      this.checkRate = Math.max(0.01, this.checkRate * 0.8);
    }
  }
}</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">PHASE 3: ALERT ONLY</h2> <p class="mb-3 font-mono">Real-time communication. You get pinged if something looks weird.</p> <p class="mb-6">Messages go through immediately. You're analyzing asyncâ€”looking for
        anomalies, sudden topic changes, confidence drops. Most of the time you
        see nothing. When something's off, you get a notification.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Alert only: human is notified, doesn't block
async function alertBasedMediation(
  from: Agent,
  to: Agent, 
  msg: Message
) {
  // Message goes through immediately
  const delivery = to.receive(msg, from.id);
  
  // But we analyze it async
  const analysis = analyzeMessage(msg, {
    conversationHistory: getHistory(from.id, to.id),
    agentProfiles: [from.profile, to.profile],
    recentMetrics: getRecentMetrics(from.id, to.id)
  });
  
  // Parallel: delivery and analysis
  const [result, score] = await Promise.all([delivery, analysis]);
  
  // Alert human only if suspicious
  if (score.anomalyScore > 0.7) {
    await notifyHuman({
      type: "anomaly-detected",
      from: from.id,
      to: to.id,
      message: msg,
      score: score,
      action: "review-conversation"
    });
  }
  
  return result;
}</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">PHASE 4: AUTONOMOUS</h2> <p class="mb-3 font-mono">Agents talk directly. You can watch the logs if you want.</p> <p class="mb-6">Full trust mode. They've done this 500 times without screwing up.
        They're just talking now. You can review conversation history if you're
        curious, but you're not in the loop. One bad exchange? They get demoted
        back to alert-only.</p></div> <div><h2 class="text-2xl font-bold font-mono mb-4">DURABLE OBJECT IMPLEMENTATION</h2> <p class="mb-3 font-mono">One DO per agent pair. Tracks conversation, trust level, metrics.</p> <p class="mb-6">The mediator is a Durable Object instance per agent pair. It holds
        conversation history, current trust level, success rates. When a message
        comes in, it routes based on trust level. When metrics update, it can
        auto-promote or demote the pair.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Durable Object per agent-pair
export class AgentPairMediator extends DurableObject {
  private history: Message[] = [];
  private trustLevel: TrustLevel = "full-mediation";
  private metrics = {
    totalMessages: 0,
    humanInterventions: 0,
    successRate: 1.0
  };
  
  async handleMessage(request: Request) {
    const { from, to, message, type } = await request.json();
    
    switch (type) {
      case "send":
        return this.mediateMessage(from, to, message);
      
      case "human-review":
        return this.handleHumanReview(message);
      
      case "update-trust":
        return this.updateTrustLevel();
      
      case "get-pending":
        return this.getPendingReviews();
    }
  }
  
  async mediateMessage(from: string, to: string, msg: Message) {
    this.history.push({ from, to, msg, timestamp: Date.now() });
    this.metrics.totalMessages++;
    
    switch (this.trustLevel) {
      case "full-mediation":
        // Block and wait for human
        await this.queueForReview(msg);
        return { status: "pending", id: msg.id };
      
      case "spot-check":
        if (Math.random() &lt; 0.1) {
          await this.queueForReview(msg);
        }
        // Fall through - deliver anyway
        
      case "alert-only":
        const score = this.analyzeMessage(msg);
        if (score > 0.7) {
          await this.alertHuman(msg, score);
        }
        // Fall through
        
      case "autonomous":
        // Just track it
        await this.deliverMessage(to, msg);
        return { status: "delivered" };
    }
  }
  
  async updateTrustLevel() {
    const { successRate, totalMessages } = this.metrics;
    
    // Escalate trust with good track record
    if (successRate > 0.95 &amp;&amp; totalMessages > 50) {
      if (this.trustLevel === "full-mediation") {
        this.trustLevel = "spot-check";
      } else if (this.trustLevel === "spot-check") {
        this.trustLevel = "alert-only";
      } else if (this.trustLevel === "alert-only") {
        this.trustLevel = "autonomous";
      }
    }
    
    // Deescalate on problems
    if (successRate &lt; 0.85) {
      if (this.trustLevel === "autonomous") {
        this.trustLevel = "alert-only";
      } else if (this.trustLevel === "alert-only") {
        this.trustLevel = "spot-check";
      }
    }
    
    await this.state.storage.put("trustLevel", this.trustLevel);
  }
}</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">HUMAN INTERFACE</h2> <p class="mb-3 font-mono">SSE stream of pending reviews. Human approves/rejects/edits.</p> <p class="mb-6">You need a UI for reviewing messages. Each agent-pair DO can push
        pending reviews to an SSE stream. Human dashboard shows all pending
        reviews across all pairs they supervise. Click approve, or edit the
        message inline, or reject with feedback.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Human review interface
interface ReviewRequest {
  id: string;
  from: string;
  to: string;
  message: Message;
  context: {
    history: Message[];
    metrics: PairMetrics;
    trustLevel: TrustLevel;
  };
}

// SSE stream of pending reviews
async function streamPendingReviews(humanId: string) {
  const stream = new ReadableStream({
    async start(controller) {
      // Get all agent-pairs this human supervises
      const pairs = await getSupvisedPairs(humanId);
      
      for (const pair of pairs) {
        const mediator = env.MEDIATOR.get(
          env.MEDIATOR.idFromName(`${pair.a}:${pair.b}`)
        );
        
        // WebSocket to each mediator DO
        const ws = await mediator.fetch("/ws");
        
        ws.addEventListener("message", (event) => {
          const review: ReviewRequest = JSON.parse(event.data);
          
          // Push to human's review queue
          controller.enqueue(
            `data: ${JSON.stringify(review)}\n\n`
          );
        });
      }
    }
  });
  
  return new Response(stream, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache"
    }
  });
}

// Human makes decision
async function submitReview(reviewId: string, decision: {
  approved: boolean;
  edited?: Message;
  feedback?: string;
}) {
  const review = await getReview(reviewId);
  const mediator = getMediatorDO(review.from, review.to);
  
  await mediator.fetch("/human-review", {
    method: "POST",
    body: JSON.stringify({ reviewId, decision })
  });
}</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">WHY THIS WORKS</h2> <div class="grid grid-cols-1 md:grid-cols-2 gap-6"><div class="border-2 border-black p-6"><h3 class="text-xl font-bold font-mono mb-4">GRADUAL TRUST</h3> <ul class="space-y-2"><li>â€¢ Don't need perfect agents day 1</li> <li>â€¢ Build confidence over time</li> <li>â€¢ Automatic promotion based on data</li> <li>â€¢ Instant demotion on problems</li></ul></div> <div class="border-2 border-black p-6"><h3 class="text-xl font-bold font-mono mb-4">ADAPTIVE OVERSIGHT</h3> <ul class="space-y-2"><li>â€¢ Heavy supervision when needed</li> <li>â€¢ Scales down as quality improves</li> <li>â€¢ Human time spent on real issues</li> <li>â€¢ Autonomous when earned</li></ul></div> <div class="border-2 border-black p-6"><h3 class="text-xl font-bold font-mono mb-4">SAFETY NET</h3> <ul class="space-y-2"><li>â€¢ Bad messages caught early</li> <li>â€¢ Feedback loop for improvement</li> <li>â€¢ Automatic rollback on failure</li> <li>â€¢ Audit trail of all decisions</li></ul></div> <div class="border-2 border-black p-6"><h3 class="text-xl font-bold font-mono mb-4">SCALABILITY</h3> <ul class="space-y-2"><li>â€¢ One human supervises many pairs</li> <li>â€¢ Only review what needs reviewing</li> <li>â€¢ Successful pairs need zero attention</li> <li>â€¢ Focus on problem cases</li></ul></div></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">USE CASES</h2> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Use case: AI coding assistants
// Two agents working on a codebase
// Human reviews their changes before merge

const codeReviewMediator = new AgentPairMediator({
  agentA: "backend-agent",
  agentB: "frontend-agent",
  trustLevel: "spot-check",
  rules: {
    // Auto-approve safe changes
    autoApprove: (msg) => {
      return msg.type === "comment" || 
             msg.linesChanged &lt; 10;
    },
    // Always review breaking changes
    requireReview: (msg) => {
      return msg.breaking === true ||
             msg.linesChanged > 100 ||
             msg.files.includes("schema.ts");
    }
  }
});

// Use case: Customer service agents
// Human steps in when confidence is low

const supportMediator = new AgentPairMediator({
  agentA: "support-bot",
  agentB: "customer",
  trustLevel: "alert-only",
  rules: {
    alertHuman: (msg) => {
      return msg.sentiment === "angry" ||
             msg.confidence &lt; 0.7 ||
             msg.topic === "refund";
    }
  }
});

// Use case: Multi-agent research
// Agents fact-check each other, human arbitrates

const researchMediator = new AgentPairMediator({
  agentA: "research-agent",
  agentB: "fact-checker",
  trustLevel: "full-mediation",
  rules: {
    requireHuman: (msg) => {
      const agreement = calculateAgreement(
        msg.researcherClaim,
        msg.factCheckerResult
      );
      return agreement &lt; 0.8; // Conflict threshold
    }
  }
});</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">REAL-WORLD SCENARIOS</h2> <div class="space-y-4"><div class="border-2 border-black p-4"><h4 class="font-bold font-mono mb-2">CODE REVIEW AGENTS</h4> <p class="text-sm mb-2">Backend agent and frontend agent working on same feature. Human
            reviews their interface contract initially. After 20 successful
            integrations, they're on spot-check. After 100, they're autonomous.</p> <p class="text-sm">One breaking change? Back to spot-check. Two in a week? Full
            mediation.</p></div> <div class="border-2 border-black p-4"><h4 class="font-bold font-mono mb-2">CUSTOMER SUPPORT HANDOFF</h4> <p class="text-sm mb-2">AI handles common questions. Human agent handles complex issues.
            When should AI escalate? Start with full mediationâ€”human approves
            every handoff.</p> <p class="text-sm">After 50 correct escalation decisions, move to spot-check. After
            500, alert-onlyâ€”human gets pinged if AI seems unsure.</p></div> <div class="border-2 border-black p-4"><h4 class="font-bold font-mono mb-2">RESEARCH COLLABORATION</h4> <p class="text-sm mb-2">Research agent finds sources. Fact-checker agent validates claims.
            They disagree? Human arbitrates.</p> <p class="text-sm">Full mediation on conflicts. If they agree 95% of the time, human
            only reviews the disagreements. Perfect track record? Just monitor.</p></div> <div class="border-2 border-black p-4"><h4 class="font-bold font-mono mb-2">TRADING SYSTEM COORDINATION</h4> <p class="text-sm mb-2">Market analysis agent suggests trades. Risk management agent checks
            exposure. Human approves initially.</p> <p class="text-sm">After 200 trades with no violations, spot-check mode. After 1000?
            Alert-only on unusual positions. Never fully autonomousâ€”some things
            need human override available.</p></div></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">IMPLEMENTATION NOTES</h2> <ul class="list-disc ml-6 space-y-2"><li><strong>Durable Object per pair:</strong> Each agent pair gets its own
          DO instance. Keyed by <code>agentA:agentB</code>. Holds conversation
          history and trust state.</li> <li><strong>Trust transitions:</strong> Don't auto-promote too fast. Need statistically
          significant sample size (e.g., 50+ exchanges with 95%+ success).</li> <li><strong>Demotion is instant:</strong> One failure at autonomous level?
          Straight to alert-only. Two failures? Full mediation. Trust is earned slowly,
          lost quickly.</li> <li><strong>Human bandwidth:</strong> One person can supervise 20-50 agent
          pairs at full mediation, hundreds at spot-check, thousands at alert-only.</li> <li><strong>Metrics matter:</strong> Track success rate, human intervention
          rate, message volume, escalation accuracy. These drive trust transitions.</li> <li><strong>Feedback loops:</strong> When human edits a message, that's training
          data. When human rejects, that's critical feedback. Use it.</li></ul></div> <div><h2 class="text-2xl font-bold font-mono mb-4">WHAT YOU'RE ACTUALLY BUILDING</h2> <p class="mb-4">This isn't just a safety mechanism. You're building a training system.</p> <p class="mb-4">Every human review is a label. Every approval is "this message was
        good." Every edit is "this is how you should have said it." Every
        rejection is "don't do that."</p> <p class="mb-4">After a few hundred reviews, you've got a dataset. Train a classifier:
        "Would human approve this message?" Now your spot-check sampling isn't
        randomâ€”it targets messages the classifier is uncertain about.</p> <p class="mb-4">After a few thousand reviews, you can train a message rewriter: "Given
        this message that human rejected, predict what human would edit it to."
        Now you're auto-correcting before messages even reach the human.</p> <p>The endgame: agents learn your review patterns. They internalize your
        communication rules. They become the agents you wanted from day 1, but
        now they got there through supervised evolution instead of prompt
        engineering guesswork.</p></div> <div><h2 class="text-2xl font-bold font-mono mb-4">THE BIGGER PICTURE</h2> <p class="mb-4">Multi-agent systems fail because we expect agents to work together
        perfectly from the start. That's not how humans work. That's not how
        teams work.</p> <p class="mb-4">Real teams start with high communication overhead. Lots of meetings,
        lots of check-ins. As they build rapport and shared context, they need
        less coordination. Eventually, they're just async shipping.</p> <p class="mb-4">Same deal here. Start with the mediator doing heavy lifting. Fade as
        agents prove they can handle it. Jump back in when they screw up.</p> <p class="mb-4">The architecture supports this. The trust levels are explicit. The
        transitions are data-driven. The human oversight scales down, not up.</p> <p>This is how you actually deploy agent-to-agent communication in
        production. Not by hoping they behave. By teaching them, monitoring
        them, and earning trust over time.</p></div> <div><h2 class="text-2xl font-bold font-mono mb-4">WHEN NOT TO USE THIS</h2> <ul class="list-disc ml-6 space-y-2"><li><strong>Agents never need oversight:</strong> If your agents are purely
          deterministic or doing simple pass-through, you don't need mediation.</li> <li><strong>No human available:</strong> Pattern requires human in loop initially.
          If no human capacity, use deterministic protocols instead.</li> <li><strong>Real-time latency critical:</strong> Full mediation adds human
          latency. If sub-second response required, start at alert-only or don't
          use pattern.</li> <li><strong>Single agent orchestrator:</strong> If you have one agent calling
          multiple subagents (primary/subagent pattern), you don't need peer mediation.</li></ul></div> <div class="border-t-2 border-black pt-6"><h3 class="text-xl font-bold font-mono mb-2">Related patterns</h3> <ul class="list-disc ml-6"><li><a class="underline" href="/agentic-architecture">Agentic AI Architectures</a></li> <li><a class="underline" href="/fleet-pattern">Fleet Pattern: Hierarchical Durable Objects</a></li> <li><a class="underline" href="/workflow-live">Workflow Live: Real-time monitoring</a></li> <li><a class="underline" href="/userdo">UserDO: Per-user state</a></li></ul></div></div></section><!----><!----></main><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_seuxg2 = {
						base: new URL(".", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("./_app/immutable/entry/start.B6XN_71n.js"),
						import("./_app/immutable/entry/app.BC487iTC.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 19],
							data: [{type:"data",data:{user:null,session:null},uses:{}},null],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
