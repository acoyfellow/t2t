<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">

		<meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="generator" content="coey.dev" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link
      rel="preconnect"
      href="https://fonts.gstatic.com"
      crossorigin="anonymous"
    />
    <link class="deferred-stylesheet" rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Google+Sans:300,400,500,600,700&family=Google+Sans+Mono:300,400,500,600,700&amp;display=swap&amp;lang=en" as="style">

		
		<link href="./_app/immutable/assets/0.-k1r2YJt.css" rel="stylesheet">
		<link href="./_app/immutable/assets/CodeBlock.mf1IAhYo.css" rel="stylesheet"><!--12qhfyh--><meta name="description" content="Developer thoughts and code"/><!----><!--ojxrft--><meta name="description" content="Run multiple AI models in parallel, merge with consensus, orchestrate with Durable Objects. One function call."/> <meta name="keywords" content="ditto, llm, ai, cloudflare, durable objects, edge computing"/> <link rel="canonical" href="https://coey.dev/ditto"/> <meta name="author" content="Jordan Coeyman"/> <!--[!--><!--]--> <meta property="og:title" content="Ditto: Edge-native parallel LLM orchestration"/> <meta property="og:description" content="Run multiple AI models in parallel, merge with consensus, orchestrate with Durable Objects. One function call."/> <meta property="og:type" content="article"/> <meta property="og:url" content="https://coey.dev/ditto"/> <meta property="og:image" content="https://api.coey.dev/?title=Ditto%3A%20Edge-native%20parallel%20LLM%20orchestration&amp;description=Run%20multiple%20AI%20models%20in%20parallel%2C%20merge%20with%20consensus%2C%20orchestrate%20with%20Durable%20Objects.%20One%20function%20call."/> <meta property="og:site_name" content="coey.dev"/> <meta name="twitter:card" content="summary_large_image"/> <meta name="twitter:title" content="Ditto: Edge-native parallel LLM orchestration"/> <meta name="twitter:description" content="Run multiple AI models in parallel, merge with consensus, orchestrate with Durable Objects. One function call."/> <meta name="twitter:image" content="https://api.coey.dev/?title=Ditto%3A%20Edge-native%20parallel%20LLM%20orchestration&amp;description=Run%20multiple%20AI%20models%20in%20parallel%2C%20merge%20with%20consensus%2C%20orchestrate%20with%20Durable%20Objects.%20One%20function%20call."/> <meta name="twitter:site" content="@acoyfellow"/> <!--[--><meta property="article:published_time" content="2025-01-21"/> <meta property="article:modified_time" content="2025-01-21"/> <!--[--><meta property="article:section" content="technical"/><!--]--> <!--[--><meta property="article:tag" content="ai,cloudflare,durable-objects"/><!--]--><!--]-->  <!----><script type="application/ld+json" nonce="%sveltekit.nonce%">{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "Jordan Coeyman",
  "url": "https://coey.dev",
  "logo": {
    "@type": "ImageObject",
    "url": "https://coey.dev/jordan.jpg"
  },
  "sameAs": [
    "https://x.com/acoyfellow",
    "https://github.com/acoyfellow"
  ]
}</script><!----> <!--[!--><!--]--> <!--[--><!----><script type="application/ld+json" nonce="%sveltekit.nonce%">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Ditto: Edge-native parallel LLM orchestration",
  "description": "Run multiple AI models in parallel, merge with consensus, orchestrate with Durable Objects. One function call.",
  "image": "https://api.coey.dev/?title=Ditto%3A%20Edge-native%20parallel%20LLM%20orchestration&description=Run%20multiple%20AI%20models%20in%20parallel%2C%20merge%20with%20consensus%2C%20orchestrate%20with%20Durable%20Objects.%20One%20function%20call.",
  "wordCount": 0,
  "author": {
    "@type": "Organization",
    "name": "Jordan Coeyman"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Jordan Coeyman",
    "logo": {
      "@type": "ImageObject",
      "url": "https://coey.dev/jordan.jpg"
    }
  },
  "datePublished": "2025-01-21",
  "dateModified": "2025-01-21",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://coey.dev/ditto"
  }
}</script><!----><!--]--> <!--[!--><!--]--><!----><title>Ditto: Edge-native parallel LLM orchestration</title>
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents"><!--[--><!--[--><!----><header class="flex items-center justify-between p-4 gap-4 flex-wrap" id="nav"><a href="/" class="px-4 py-2 md:px-8 md:py-4 md:text-2xl font-black hover:bg-white hover:text-black border-4 border-black hover:border-white bg-white text-black">coey.dev</a> <nav><div class="flex gap-0"><a href="/" class="px-4 py-2 md:px-8 md:py-4 md:text-2xl font-black hover:bg-white hover:text-black border-4 border-black bg-white text-black">POSTS</a> <a href="/about" class="px-4 py-2 md:px-8 md:py-4 md:text-2xl font-black hover:bg-black hover:text-white border-4 border-black border-l-0 bg-white text-black">ABOUT</a></div></nav></header> <div class="fixed inset-0 pointer-events-none -z-10" style="opacity: 0.7; mix-blend-mode: multiply; will-change: transform;"></div><!----> <main class="pt-20 relative"><!----><!----> <main class="bg-white text-black"><div class="max-w-4xl mx-auto px-6 py-12"><header class="border-b-2 border-black pb-8 mb-12"><h1 class="text-4xl font-bold uppercase tracking-wider mb-4">DITTO: EDGE-NATIVE PARALLEL LLM ORCHESTRATION</h1> <p class="text-xl font-mono">Multiple models. One call. Consensus merging.</p> <div class="mt-4 font-mono"><span class="bg-black text-white px-2 py-1">TECHNICAL GUIDE</span> <span class="ml-4">2025.11.21</span></div></header> <p class="text-lg font-mono mb-6">Run multiple AI models in parallel, merge their outputs with consensus,
      get back typed results. Built on Durable Objects for durability and
      idempotency.</p> <section class="mb-12 grid grid-cols-1 md:grid-cols-3 gap-4"><a href="https://ditto.coey.dev" target="_blank" rel="noopener noreferrer" class="bg-black text-white px-8 py-6 text-2xl font-black border-4 border-black hover:bg-white hover:text-black transition-colors duration-100 text-center">VIEW DEMO</a> <a href="https://github.com/acoyfellow/ditto" target="_blank" rel="noopener noreferrer" class="bg-white text-black px-8 py-6 text-2xl font-black border-4 border-black hover:bg-black hover:text-white transition-colors duration-100 text-center">VIEW REPO</a> <a href="https://www.npmjs.com/package/ditto-ai" target="_blank" rel="noopener noreferrer" class="bg-black text-white px-8 py-6 text-2xl font-black border-4 border-black hover:bg-white hover:text-black transition-colors duration-100 text-center">NPM PACKAGE</a></section> <section class="mb-12 border-l-2 border-black pl-6"><h2 class="text-2xl font-bold font-mono mb-4">THE QUICK VERSION</h2> <p class="text-lg leading-relaxed mb-4">Single model = fragile. Multiple models in parallel = robust + fewer
        hallucinations. But combining N different API calls = tedious.</p> <p class="text-lg leading-relaxed mb-4">Ditto handles the orchestration. You call one function. It runs models
        in parallel using Effect for true concurrency, merges outputs with
        consensus or cooperative strategies, tracks individual responses, and
        returns typed results.</p> <p class="leading-relaxed">Per-request Durable Object job. Effect-based execution. Unlimited
        concurrency. All on the edge.</p></section></div></main> <section class="mb-16 max-w-4xl mx-auto"><h2 class="text-2xl font-bold font-mono mb-6">ARCHITECTURE</h2> <div class="bg-black text-white p-4 font-mono mb-8"><pre>Client â†’ Worker â†’ JobDO (per request)
           â†“         â†“
        Effect.all  Parallel model calls
           â†“         â†“
        Consensus   Merged result</pre></div> <h2 class="text-2xl font-bold font-mono mb-4">WHY PARALLEL MODELS?</h2> <p class="mb-3 font-mono">Single models fail. Multiple models agree = higher confidence.</p> <div class="border-2 border-black mb-8"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Why parallel models?

// Single model = fragile
const single = await ai.run("@cf/meta/llama-3.1-8b-instruct", { prompt });
// One failure = complete failure
// One hallucination = wrong answer

// Multiple models in parallel = robust
const multi = await ditto({
  prompt,
  models: [
    "@cf/meta/llama-3.1-8b-instruct",
    "@cf/mistral/mistral-7b-instruct",
    "@cf/qwen/qwen-2.5-7b-instruct"
  ],
  strategy: "consensus"
});
// Majority agreement = higher confidence
// Disagreement = flag for review
// One failure = others continue</code></pre><!--]--><!----></div> <h2 class="text-2xl font-bold font-mono mb-4">CLIENT</h2> <p class="mb-3 font-mono">Install ditto-ai, call one function. Get merged results with confidence
    scores.</p> <div class="border-2 border-black mb-8"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// client.ts
import { dittoClient } from "ditto-ai";

const ditto = dittoClient({
  endpoint: "https://your-worker.workers.dev/llm",
});

const response = await ditto({
  prompt: "Summarize this email...",
  models: [
    "@cf/meta/llama-3.1-8b-instruct",
    "@cf/mistral/mistral-7b-instruct"
  ],
  strategy: "consensus",
});

console.log(response.result);      // merged output
console.log(response.structured);  // intent, confidence, supporting models
console.log(response.responses);   // individual model outputs
console.log(response.timings);     // total, fanout, slowest, merge time</code></pre><!--]--><!----></div> <h2 class="text-2xl font-bold font-mono mb-4">INFRASTRUCTURE</h2> <p class="mb-3 font-mono">One namespace, one Workerâ€”Alchemy wires the bindings.</p> <div class="border-2 border-black mb-8"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// alchemy.run.ts
import alchemy from "alchemy";
import { Worker, DurableObjectNamespace } from "alchemy/cloudflare";

const app = await alchemy("ditto");

const jobs = DurableObjectNamespace("job", { className: "JobDO" });

await Worker("api", {
  entrypoint: "./src/worker.ts",
  bindings: { JOBS: jobs, AI: "AI" }
});

await app.finalize();</code></pre><!--]--><!----></div> <h2 class="text-2xl font-bold font-mono mb-4">WORKER</h2> <p class="mb-3 font-mono">Create per-request job DO. Poll for result or use WebSocket for real-time.</p> <div class="border-2 border-black mb-8"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// src/worker.ts
import { Hono } from 'hono';
import { createJob, getJobResult } from './job';

const app = new Hono();

app.post('/llm', async (c) => {
  const { prompt, models, strategy } = await c.req.json();
  
  const jobId = crypto.randomUUID();
  const stub = c.env.JOBS.get(c.env.JOBS.idFromName(jobId));
  
  // Create job DO, runs models in parallel
  await stub.fetch('https://do/start', {
    method: 'POST',
    body: JSON.stringify({ prompt, models, strategy })
  });
  
  // Poll for result (or use WebSocket for real-time)
  const result = await getJobResult(stub);
  
  return c.json(result);
});

export default app;</code></pre><!--]--><!----></div> <h2 class="text-2xl font-bold font-mono mb-4">JOB DURABLE OBJECT</h2> <p class="mb-3 font-mono">Effect.all runs models in parallel with unbounded concurrency. Merge based
    on strategy.</p> <div class="border-2 border-black mb-8"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// src/job.ts (Durable Object)
import { DurableObject } from "cloudflare:workers";
import { Effect } from "effect";

export class JobDO extends DurableObject {
  private state: 'pending' | 'running' | 'complete' | 'error' = 'pending';
  private responses: any[] = [];
  private result: any = null;

  async fetch(req: Request) {
    const url = new URL(req.url);
    
    if (url.pathname === '/start' &amp;&amp; req.method === 'POST') {
      const { prompt, models, strategy } = await req.json();
      
      // Effect.all runs models in parallel
      const program = Effect.all(
        models.map(model => 
          Effect.tryPromise({
            try: () => this.callModel(model, prompt),
            catch: (error) => new Error(`Model ${model} failed`)
          })
        ),
        { concurrency: 'unbounded' }
      );
      
      // Execute with Effect runtime
      const responses = await Effect.runPromise(program);
      this.responses = responses;
      
      // Merge based on strategy
      this.result = strategy === 'consensus' 
        ? this.mergeConsensus(responses)
        : this.mergeCooperative(responses);
      
      this.state = 'complete';
      return Response.json({ success: true });
    }
    
    if (url.pathname === '/result') {
      return Response.json({
        state: this.state,
        result: this.result,
        responses: this.responses
      });
    }
    
    return new Response('not found', { status: 404 });
  }
  
  private async callModel(model: string, prompt: string) {
    const response = await this.env.AI.run(model, {
      messages: [{ role: 'user', content: prompt }]
    });
    return { model, output: response.response };
  }
  
  private mergeConsensus(responses: any[]) {
    // Confidence scoring, majority voting, etc.
    return {
      result: responses[0].output, // simplified
      structured: {
        confidence: 0.92,
        supportingModels: responses.map(r => r.model)
      }
    };
  }
  
  private mergeCooperative(responses: any[]) {
    // Sequential building, each model refines previous
    return { result: responses[responses.length - 1].output };
  }
}</code></pre><!--]--><!----></div> <h2 class="text-2xl font-bold font-mono mb-4">STRATEGIES</h2> <p class="mb-3 font-mono">Consensus: parallel merge with confidence scoring. Cooperative: sequential,
    models build on each other.</p> <div class="border-2 border-black mb-4"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Strategies

// CONSENSUS: Parallel merge with confidence scoring
const consensus = await ditto({
  prompt: "Is this email urgent?",
  models: ["@cf/meta/llama-3.1-8b-instruct", "@cf/mistral/mistral-7b-instruct"],
  strategy: "consensus"
});
// Returns: merged output + confidence score + supporting models

// COOPERATIVE: Sequential, models build on each other
const cooperative = await ditto({
  prompt: "Extract key points, then summarize",
  models: ["@cf/meta/llama-3.1-8b-instruct", "@cf/mistral/mistral-7b-instruct"],
  strategy: "cooperative"
});
// Returns: final refined output</code></pre><!--]--><!----></div> <div class="mt-12 border-t-2 border-black pt-6"><h3 class="text-xl font-bold font-mono mb-2">Other articles</h3> <ul class="list-disc ml-6"><li><a class="underline" href="/agentic-architecture">Agentic Architecture</a></li> <li><a class="underline" href="/bio">Bio: Single-button WebAuthn auth</a></li> <li><a class="underline" href="/userdo">UserDO: Per-user Durable Objects</a></li> <li><a class="underline" href="/blaze">Blaze: Real-time documents</a></li></ul></div></section><!----><!----></main><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_seuxg2 = {
						base: new URL(".", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("./_app/immutable/entry/start.B6XN_71n.js"),
						import("./_app/immutable/entry/app.BC487iTC.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 10],
							data: [{type:"data",data:{user:null,session:null},uses:{}},{type:"data",data:{code:{alchemyTs:"// alchemy.run.ts\nimport alchemy from \"alchemy\";\nimport { Worker, DurableObjectNamespace } from \"alchemy/cloudflare\";\n\nconst app = await alchemy(\"ditto\");\n\nconst jobs = DurableObjectNamespace(\"job\", { className: \"JobDO\" });\n\nawait Worker(\"api\", {\n  entrypoint: \"./src/worker.ts\",\n  bindings: { JOBS: jobs, AI: \"AI\" }\n});\n\nawait app.finalize();",clientTs:"// client.ts\nimport { dittoClient } from \"ditto-ai\";\n\nconst ditto = dittoClient({\n  endpoint: \"https://your-worker.workers.dev/llm\",\n});\n\nconst response = await ditto({\n  prompt: \"Summarize this email...\",\n  models: [\n    \"@cf/meta/llama-3.1-8b-instruct\",\n    \"@cf/mistral/mistral-7b-instruct\"\n  ],\n  strategy: \"consensus\",\n});\n\nconsole.log(response.result);      // merged output\nconsole.log(response.structured);  // intent, confidence, supporting models\nconsole.log(response.responses);   // individual model outputs\nconsole.log(response.timings);     // total, fanout, slowest, merge time",workerTs:"// src/worker.ts\nimport { Hono } from 'hono';\nimport { createJob, getJobResult } from './job';\n\nconst app = new Hono();\n\napp.post('/llm', async (c) => {\n  const { prompt, models, strategy } = await c.req.json();\n  \n  const jobId = crypto.randomUUID();\n  const stub = c.env.JOBS.get(c.env.JOBS.idFromName(jobId));\n  \n  // Create job DO, runs models in parallel\n  await stub.fetch('https://do/start', {\n    method: 'POST',\n    body: JSON.stringify({ prompt, models, strategy })\n  });\n  \n  // Poll for result (or use WebSocket for real-time)\n  const result = await getJobResult(stub);\n  \n  return c.json(result);\n});\n\nexport default app;",jobDoTs:"// src/job.ts (Durable Object)\nimport { DurableObject } from \"cloudflare:workers\";\nimport { Effect } from \"effect\";\n\nexport class JobDO extends DurableObject {\n  private state: 'pending' | 'running' | 'complete' | 'error' = 'pending';\n  private responses: any[] = [];\n  private result: any = null;\n\n  async fetch(req: Request) {\n    const url = new URL(req.url);\n    \n    if (url.pathname === '/start' && req.method === 'POST') {\n      const { prompt, models, strategy } = await req.json();\n      \n      // Effect.all runs models in parallel\n      const program = Effect.all(\n        models.map(model => \n          Effect.tryPromise({\n            try: () => this.callModel(model, prompt),\n            catch: (error) => new Error(`Model ${model} failed`)\n          })\n        ),\n        { concurrency: 'unbounded' }\n      );\n      \n      // Execute with Effect runtime\n      const responses = await Effect.runPromise(program);\n      this.responses = responses;\n      \n      // Merge based on strategy\n      this.result = strategy === 'consensus' \n        ? this.mergeConsensus(responses)\n        : this.mergeCooperative(responses);\n      \n      this.state = 'complete';\n      return Response.json({ success: true });\n    }\n    \n    if (url.pathname === '/result') {\n      return Response.json({\n        state: this.state,\n        result: this.result,\n        responses: this.responses\n      });\n    }\n    \n    return new Response('not found', { status: 404 });\n  }\n  \n  private async callModel(model: string, prompt: string) {\n    const response = await this.env.AI.run(model, {\n      messages: [{ role: 'user', content: prompt }]\n    });\n    return { model, output: response.response };\n  }\n  \n  private mergeConsensus(responses: any[]) {\n    // Confidence scoring, majority voting, etc.\n    return {\n      result: responses[0].output, // simplified\n      structured: {\n        confidence: 0.92,\n        supportingModels: responses.map(r => r.model)\n      }\n    };\n  }\n  \n  private mergeCooperative(responses: any[]) {\n    // Sequential building, each model refines previous\n    return { result: responses[responses.length - 1].output };\n  }\n}",strategiesTs:"// Strategies\n\n// CONSENSUS: Parallel merge with confidence scoring\nconst consensus = await ditto({\n  prompt: \"Is this email urgent?\",\n  models: [\"@cf/meta/llama-3.1-8b-instruct\", \"@cf/mistral/mistral-7b-instruct\"],\n  strategy: \"consensus\"\n});\n// Returns: merged output + confidence score + supporting models\n\n// COOPERATIVE: Sequential, models build on each other\nconst cooperative = await ditto({\n  prompt: \"Extract key points, then summarize\",\n  models: [\"@cf/meta/llama-3.1-8b-instruct\", \"@cf/mistral/mistral-7b-instruct\"],\n  strategy: \"cooperative\"\n});\n// Returns: final refined output",whyTs:"// Why parallel models?\n\n// Single model = fragile\nconst single = await ai.run(\"@cf/meta/llama-3.1-8b-instruct\", { prompt });\n// One failure = complete failure\n// One hallucination = wrong answer\n\n// Multiple models in parallel = robust\nconst multi = await ditto({\n  prompt,\n  models: [\n    \"@cf/meta/llama-3.1-8b-instruct\",\n    \"@cf/mistral/mistral-7b-instruct\",\n    \"@cf/qwen/qwen-2.5-7b-instruct\"\n  ],\n  strategy: \"consensus\"\n});\n// Majority agreement = higher confidence\n// Disagreement = flag for review\n// One failure = others continue"}},uses:{}}],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
