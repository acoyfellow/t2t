<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">

		<meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="generator" content="coey.dev" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link
      rel="preconnect"
      href="https://fonts.gstatic.com"
      crossorigin="anonymous"
    />
    <link class="deferred-stylesheet" rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Google+Sans:300,400,500,600,700&family=Google+Sans+Mono:300,400,500,600,700&amp;display=swap&amp;lang=en" as="style">

		
		<link href="./_app/immutable/assets/0.-k1r2YJt.css" rel="stylesheet">
		<link href="./_app/immutable/assets/CodeBlock.mf1IAhYo.css" rel="stylesheet"><!--12qhfyh--><meta name="description" content="Developer thoughts and code"/><!----><!--ojxrft--><meta name="description" content="Forms are everywhere. Voice AI is getting good. What breaks first?"/> <meta name="keywords" content="post-form, voice ai, interfaces, forms, ai"/> <link rel="canonical" href="https://coey.dev/post-form"/> <meta name="author" content="Jordan Coeyman"/> <!--[!--><!--]--> <meta property="og:title" content="Post-Form Web: What happens when interfaces stop asking nicely"/> <meta property="og:description" content="Forms are everywhere. Voice AI is getting good. What breaks first?"/> <meta property="og:type" content="article"/> <meta property="og:url" content="https://coey.dev/post-form"/> <meta property="og:image" content="https://api.coey.dev/?title=Post-Form%20Web%3A%20What%20happens%20when%20interfaces%20stop%20asking%20nicely&amp;description=Forms%20are%20everywhere.%20Voice%20AI%20is%20getting%20good.%20What%20breaks%20first%3F"/> <meta property="og:site_name" content="coey.dev"/> <meta name="twitter:card" content="summary_large_image"/> <meta name="twitter:title" content="Post-Form Web: What happens when interfaces stop asking nicely"/> <meta name="twitter:description" content="Forms are everywhere. Voice AI is getting good. What breaks first?"/> <meta name="twitter:image" content="https://api.coey.dev/?title=Post-Form%20Web%3A%20What%20happens%20when%20interfaces%20stop%20asking%20nicely&amp;description=Forms%20are%20everywhere.%20Voice%20AI%20is%20getting%20good.%20What%20breaks%20first%3F"/> <meta name="twitter:site" content="@acoyfellow"/> <!--[--><meta property="article:published_time" content="2025-10-14"/> <meta property="article:modified_time" content="2025-10-14"/> <!--[--><meta property="article:section" content="technical"/><!--]--> <!--[--><meta property="article:tag" content="ai,ux,voice"/><!--]--><!--]-->  <!----><script type="application/ld+json" nonce="%sveltekit.nonce%">{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "Jordan Coeyman",
  "url": "https://coey.dev",
  "logo": {
    "@type": "ImageObject",
    "url": "https://coey.dev/jordan.jpg"
  },
  "sameAs": [
    "https://x.com/acoyfellow",
    "https://github.com/acoyfellow"
  ]
}</script><!----> <!--[!--><!--]--> <!--[--><!----><script type="application/ld+json" nonce="%sveltekit.nonce%">{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Post-Form Web: What happens when interfaces stop asking nicely",
  "description": "Forms are everywhere. Voice AI is getting good. What breaks first?",
  "image": "https://api.coey.dev/?title=Post-Form%20Web%3A%20What%20happens%20when%20interfaces%20stop%20asking%20nicely&description=Forms%20are%20everywhere.%20Voice%20AI%20is%20getting%20good.%20What%20breaks%20first%3F",
  "wordCount": 0,
  "author": {
    "@type": "Organization",
    "name": "Jordan Coeyman"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Jordan Coeyman",
    "logo": {
      "@type": "ImageObject",
      "url": "https://coey.dev/jordan.jpg"
    }
  },
  "datePublished": "2025-10-14",
  "dateModified": "2025-10-14",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://coey.dev/post-form"
  }
}</script><!----><!--]--> <!--[!--><!--]--><!----><title>Post-Form Web: What happens when interfaces stop asking nicely</title>
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents"><!--[--><!--[--><!----><header class="flex items-center justify-between p-4 gap-4 flex-wrap" id="nav"><a href="/" class="px-4 py-2 md:px-8 md:py-4 md:text-2xl font-black hover:bg-white hover:text-black border-4 border-black hover:border-white bg-white text-black">coey.dev</a> <nav><div class="flex gap-0"><a href="/" class="px-4 py-2 md:px-8 md:py-4 md:text-2xl font-black hover:bg-white hover:text-black border-4 border-black bg-white text-black">POSTS</a> <a href="/about" class="px-4 py-2 md:px-8 md:py-4 md:text-2xl font-black hover:bg-black hover:text-white border-4 border-black border-l-0 bg-white text-black">ABOUT</a></div></nav></header> <div class="fixed inset-0 pointer-events-none -z-10" style="opacity: 0.7; mix-blend-mode: multiply; will-change: transform;"></div><!----> <main class="pt-20 relative"><!----><!--[--><!--]--> <main class="bg-white text-black"><div class="max-w-4xl mx-auto px-6 py-12"><header class="border-b-2 border-black pb-8 mb-12"><h1 class="text-4xl font-bold uppercase tracking-wider mb-4">POST-FORM WEB</h1> <p class="text-xl font-mono">What interfaces look like when AI can parse intent instead of requiring
        47 fields</p> <div class="mt-4 font-mono"><span class="bg-black text-white px-2 py-1">INTERFACE EVOLUTION</span> <span class="ml-4">2025.10.14</span></div></header> <section class="mb-12 border-l-2 border-black pl-6"><h2 class="text-2xl font-bold font-mono mb-4">THE CURRENT STATE</h2> <p class="text-lg leading-relaxed mb-4">The web is forms. Sign up form. Login form. Checkout form. Preferences
        form. Contact form. Support ticket form. Job application form.</p> <p class="text-lg leading-relaxed mb-4">Forms exist because computers are stupid. They need structured input.
        Specific field types. Validation patterns. Dropdowns with predetermined
        options.</p> <p class="text-lg leading-relaxed">AI changes that equation. If a system can understand "book me a flight
        to Tokyo next week business class," why are we still filling out 12 form
        fields?</p></section> <section class="mb-12"><h2 class="text-2xl font-bold font-mono mb-4">THE OBVIOUS FUTURE</h2> <p class="leading-relaxed mb-4">Voice interfaces. Just talk. "Transfer $500 to Alex." Done. "What's my
        balance?" Answered. "Find me Italian restaurants nearby." Showing
        results.</p> <p class="leading-relaxed mb-4">No more hunting for the right dropdown option. No more validation
        errors. No more "Please enter a valid email address."</p> <p class="leading-relaxed">Exceptâ€”it's not that simple. Forms exist for good reasons. Structure is
        useful. Seeing all options matters. Some interactions need precision.</p></section> <section class="mb-12"><h2 class="text-2xl font-bold font-mono mb-4">THE ACTUAL FUTURE</h2> <p class="leading-relaxed mb-4">Not pure voice. Not pure forms. A spectrum based on task complexity,
        user context, and risk level.</p> <p class="leading-relaxed">Simple queries â†’ pure voice. Complex workflows â†’ hybrid. High-stakes
        decisions â†’ structured checkpoints. The interface adapts.</p></section></div></main> <section class="p-8"><div class="max-w-4xl mx-auto space-y-10"><div><h2 class="text-2xl font-bold font-mono mb-4">TRADITIONAL FORMS (BASELINE)</h2> <p class="mb-3 font-mono">What we have now. Structured, explicit, dumb.</p> <p class="mb-6">47 fields. Three sections. Validation on every field. Pattern matching
        on phone numbers. Date pickers that make you click through 30 years to
        find your birth year. The user does all the work.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>&lt;!-- Traditional: 47 fields, 3 sections, validation hell -->
&lt;form action="/submit" method="POST">
  &lt;section class="personal-info">
    &lt;label>First Name &lt;input type="text" required />&lt;/label>
    &lt;label>Last Name &lt;input type="text" required />&lt;/label>
    &lt;label>Email &lt;input type="email" required />&lt;/label>
    &lt;label>Phone &lt;input type="tel" pattern="[0-9]{3}-[0-9]{3}-[0-9]{4}" />&lt;/label>
    &lt;label>DOB &lt;input type="date" max="2006-01-01" />&lt;/label>
    &lt;!-- 42 more fields... -->
  &lt;/section>
  &lt;section class="preferences">
    &lt;label>
      &lt;input type="checkbox" name="newsletter" />
      Send me emails I'll never read
    &lt;/label>
    &lt;label>
      Communication Preference:
      &lt;select>
        &lt;option>Email&lt;/option>
        &lt;option>SMS&lt;/option>
        &lt;option>Carrier Pigeon&lt;/option>
      &lt;/select>
    &lt;/label>
  &lt;/section>
  &lt;button type="submit">Submit (and pray validation passes)&lt;/button>
&lt;/form></code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">PURE CONVERSATIONAL (THE DREAM)</h2> <p class="mb-3 font-mono">No form. Just talk. AI extracts structure from conversation.</p> <p class="mb-6">User says what they want in natural language. AI asks clarifying
        questions. Extracts structured data from the conversation. Executes when
        it has enough info.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Pure conversation: no form at all
async function handleUserMessage(message: string, context: Context) {
  const response = await ai.chat({
    messages: [
      { role: "system", content: "You're helping user book a flight." },
      ...context.history,
      { role: "user", content: message }
    ]
  });
  
  // Extract structured data from conversation
  const extracted = await ai.extract({
    text: response,
    schema: {
      departure: "string",
      destination: "string", 
      date: "date",
      passengers: "number",
      class: "economy | business | first"
    }
  });
  
  // Update context with extracted info
  context.flightPreferences = { ...context.flightPreferences, ...extracted };
  
  // Check if we have everything
  if (isComplete(context.flightPreferences)) {
    return await bookFlight(context.flightPreferences);
  }
  
  return { message: response, data: context };
}

// User: "I need to fly to Tokyo next week"
// AI: "Great! I can help with that. What city are you departing from?"
// User: "SF"
// AI: "Perfect. How many passengers?"
// User: "Just me"
// AI: "Got it. I found flights from San Francisco to Tokyo next Tuesday..."</code></pre><!--]--><!----></div> <div class="mt-4 p-4 border-2 border-black bg-gray-50"><h4 class="font-bold font-mono mb-2">WHEN THIS WORKS</h4> <ul class="list-disc ml-6 space-y-1 text-sm"><li>Simple, common tasks (booking, transferring, checking)</li> <li>Mobile-first contexts (driving, walking)</li> <li>Users who hate forms (most people)</li> <li>Low-stakes decisions (small amounts, reversible)</li></ul></div> <div class="mt-4 p-4 border-2 border-black bg-gray-50"><h4 class="font-bold font-mono mb-2">WHEN THIS FAILS</h4> <ul class="list-disc ml-6 space-y-1 text-sm"><li>Complex workflows with many dependencies</li> <li>Need to see all options at once</li> <li>Precise data entry (coordinates, codes, IDs)</li> <li>Legal/compliance requirements for explicit consent</li></ul></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">HYBRID: CONVERSATION + CONFIRMATION</h2> <p class="mb-3 font-mono">Talk freely, confirm with structure. Best of both.</p> <p class="mb-6">User describes what they want conversationally. AI extracts structured
        data. Shows a form pre-filled with the extraction. User reviews, edits
        if AI got something wrong, submits. Fast path for correct extractions,
        escape hatch for errors.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Hybrid: conversation + structured confirmation
interface HybridBooking {
  mode: "conversation" | "form";
  extractedData: Partial&lt;FlightBooking>;
  confidence: number;
}

async function handleInput(input: string | FormData) {
  if (typeof input === "string") {
    // Natural language input
    const extracted = await extractFlightInfo(input);
    
    if (extracted.confidence > 0.9) {
      // High confidence: show structured confirmation
      return {
        mode: "form",
        data: extracted.data,
        message: "Here's what I understood. Look good?"
      };
    } else {
      // Low confidence: ask clarifying questions
      return {
        mode: "conversation",
        message: await generateClarification(extracted)
      };
    }
  } else {
    // Structured form submission
    return await bookFlight(Object.fromEntries(input));
  }
}

// Flow:
// 1. User: "Book me a flight to Tokyo next week business class"
// 2. AI extracts: { destination: "Tokyo", date: "2025-10-21", class: "business" }
// 3. Shows form pre-filled with extraction
// 4. User edits departure city (AI guessed wrong)
// 5. Submit button â†’ done</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">INTENT-BASED ROUTING</h2> <p class="mb-3 font-mono">Different tasks need different interfaces. Route accordingly.</p> <p class="mb-6">Simple queries get instant answers. Quick transactions get
        confirmations. Complex workflows get structured forms. Exploratory
        questions get conversations. The system decides which interface fits the
        intent.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Route to appropriate interface based on intent
async function routeIntent(input: string): Promise&lt;InterfaceMode> {
  const intent = await classifyIntent(input);
  
  switch (intent.type) {
    case "quick_lookup":
      // "What's my balance?" â†’ instant answer, no form
      return { type: "instant", handler: queryBalance };
    
    case "simple_transaction":
      // "Send $50 to Alex" â†’ confirm + execute
      return { type: "confirmation", data: intent.extracted };
    
    case "complex_workflow":
      // "I need to refinance my mortgage" â†’ structured form
      // Too many variables, too important to guess
      return { type: "form", formId: "mortgage-application" };
    
    case "exploration":
      // "What are my investment options?" â†’ conversational
      return { type: "conversation", agent: "investment-advisor" };
    
    case "ambiguous":
      // Not clear what user wants
      return { type: "clarification" };
  }
}

// The interface adapts to task complexity
// Simple â†’ voice/chat
// Complex â†’ structured
// Ambiguous â†’ clarify first</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">VOICE-FIRST WITH FALLBACK</h2> <p class="mb-3 font-mono">Default to voice. Offer structure when voice fails.</p> <p class="mb-6">Start with voice input. If transcription confidence is low, offer a
        form. If user is in a noisy environment, switch to typing. If the task
        is too complex for voice, show structure. Voice is primary, not
        exclusive.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Voice-first, but structure available
interface VoiceInterface {
  transcript: string;
  confidence: number;
  extracted: Record&lt;string, any>;
  
  // Escape hatch to form
  showForm(): void;
}

async function handleVoiceInput(audio: Blob): Promise&lt;VoiceInterface> {
  // Transcribe
  const transcript = await transcribe(audio);
  
  // Extract intent + data
  const { intent, data, confidence } = await extract(transcript);
  
  if (confidence &lt; 0.7) {
    // Can't understand â†’ offer structured alternative
    return {
      transcript,
      confidence,
      extracted: data,
      message: "I didn't quite catch that. Want to fill out a quick form instead?",
      showForm: () => renderForm(intent)
    };
  }
  
  // High confidence â†’ proceed with voice
  return processIntent(intent, data);
}

// Voice works until it doesn't
// Then fallback to structure
// User chooses modality based on context</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">STREAMING FORM FILL</h2> <p class="mb-3 font-mono">Talk while watching the form populate itself.</p> <p class="mb-6">User speaks. AI transcribes and extracts in real-time. Form fields
        populate as data is extracted. User sees what's being captured. Can
        override any field. Submit when done talking. Visual feedback on voice
        extraction.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// AI fills form as you talk
class StreamingFormFiller {
  private form: HTMLFormElement;
  private ai: AIStream;
  
  async listenAndFill() {
    const stream = await this.ai.transcribeStream();
    
    for await (const chunk of stream) {
      const extracted = await this.extract(chunk.text);
      
      // Update form fields in real-time
      for (const [field, value] of Object.entries(extracted)) {
        const input = this.form.elements.namedItem(field);
        if (input &amp;&amp; !input.value) {
          // Only fill empty fields
          input.value = value;
          this.highlightField(input); // Show what just filled
        }
      }
    }
  }
}

// User speaks, form populates itself
// Can see extraction happening live
// Override any field if AI gets it wrong
// Submit when done talking</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">CONTEXT-AWARE FORMS</h2> <p class="mb-3 font-mono">Forms that pre-fill from context. Still structured, just smarter.</p> <p class="mb-6">Not conversational. Still a form. But it knows who you are, what you
        usually do, what you just looked at. Pre-fills likely values. Hides
        irrelevant fields. Adjusts based on user tier and history. Form that
        does half the work.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Forms that know what you mean
async function renderSmartForm(context: UserContext) {
  const baseForm = getFormTemplate("transfer");
  
  // Pre-fill from context
  if (context.recentlyViewedContact) {
    baseForm.recipient = context.recentlyViewedContact;
  }
  
  if (context.typicalTransferAmount) {
    baseForm.amount = context.typicalTransferAmount;
    baseForm.amountConfidence = "This is your usual amount";
  }
  
  // Adjust fields based on user
  if (context.userTier === "premium") {
    baseForm.addField({
      name: "priority",
      label: "Rush transfer?",
      default: false
    });
  }
  
  // Remove unnecessary fields
  if (context.hasSingleAccount) {
    baseForm.removeField("fromAccount");
    baseForm.metadata.fromAccount = context.accounts[0].id;
  }
  
  return baseForm;
}

// Form knows who you are
// Hides irrelevant fields
// Pre-fills likely values
// Still structured, just smarter</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">PROGRESSIVE DISCLOSURE</h2> <p class="mb-3 font-mono">Only show fields as they become relevant.</p> <p class="mb-6">Don't show all 47 fields upfront. Show the first question. Based on the
        answer, AI determines what to ask next. Skip fields that can be
        inferred. Hide options that don't apply. Form adapts to user's specific
        path.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Only show fields as needed
class AdaptiveForm {
  private fields: Field[] = [];
  private shownFields: Set&lt;string> = new Set();
  
  async processInput(field: string, value: any) {
    // User filled a field
    this.data[field] = value;
    
    // Determine what to show next based on AI
    const next = await this.ai.determineNextFields({
      template: this.formTemplate,
      currentData: this.data,
      userContext: this.context
    });
    
    // Show only relevant next fields
    for (const field of next.fields) {
      if (!this.shownFields.has(field.name)) {
        this.renderField(field);
        this.shownFields.add(field.name);
      }
    }
    
    // Hide fields that became irrelevant
    for (const field of next.hideFields) {
      this.hideField(field);
      this.shownFields.delete(field);
    }
  }
}

// Booking flight:
// 1. Shows: destination
// 2. User enters "Tokyo"
// 3. AI shows: date (not origin, guessed from IP)
// 4. User enters date
// 5. AI shows: class preference (detected multi-day trip)
// 6. Never shows: number of bags (business class includes 2)

// Form adapts to user's answers
// Only ask what matters
// Skip what can be inferred</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">FORM AS CHECKPOINT</h2> <p class="mb-3 font-mono">Conversation for collection. Form for confirmation.</p> <p class="mb-6">Free-form conversation to gather requirements. Extract structured data
        from conversation. Show form pre-filled with extraction as review step.
        User edits if needed. Execute with validated data. Form becomes the
        checkpoint, not the interface.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Conversation â†’ Form â†’ Execution
async function conversationToExecution(sessionId: string) {
  // Phase 1: Free-form conversation
  const conversation = await runConversation(sessionId, {
    goal: "Understand user's insurance needs"
  });
  
  // Phase 2: Extract structured data
  const extracted = await extractFromConversation(conversation.messages);
  
  // Phase 3: Show form as checkpoint
  const form = await generateForm({
    template: "insurance-application",
    prefill: extracted,
    editable: true,
    validations: true
  });
  
  // User reviews/edits the structured extraction
  const reviewed = await waitForFormSubmission(form);
  
  // Phase 4: Execute with validated data
  return await submitApplication(reviewed);
}

// Talk freely (conversation)
// Review what was understood (form)
// Confirm and submit (execution)

// Form is the checkpoint, not the interface</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">NO FORM AT ALL</h2> <p class="mb-3 font-mono">Some interactions genuinely don't need forms.</p> <p class="mb-6">Balance check? Just answer. Small transfer to known contact? Execute
        directly with voice confirmation. Pay recurring bill? Done. No form was
        needed. No form was shown. Voice command to action.</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Some things don't need forms anymore
interface VoiceCommand {
  utterance: string;
  intent: Intent;
  execute: boolean;
}

async function handleCommand(audio: Blob) {
  const command = await parseVoiceCommand(audio);
  
  switch (command.intent) {
    case "check_balance":
      // No form needed, just answer
      return await getBalance(command.params.account);
    
    case "send_money":
      // Need confirmation, but no form
      const amount = command.params.amount;
      const to = command.params.recipient;
      
      if (amount > 1000) {
        // Confirm via voice
        const confirm = await askConfirmation(
          `Send $${amount} to ${to}?`
        );
        if (!confirm) return { cancelled: true };
      }
      
      return await transfer(command.params);
    
    case "pay_bill":
      // Recurring action, no form
      const bill = await findBill(command.params.billName);
      return await payBill(bill.id);
  }
}

// User: "What's my balance?"
// AI: "$3,247.82"
// (no form was harmed in this transaction)

// User: "Send Alex $50"
// AI: "Sent."
// (still no form)

// User: "Pay my electric bill"
// AI: "Paid $127.43 to PG&amp;E."
// (forms have left the chat)</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">THE SPECTRUM</h2> <div class="border-2 border-black p-6"><pre class="font-mono text-sm whitespace-pre-wrap">
TASK COMPLEXITY vs INTERFACE MODE

Simple/Low-Stakes           Complex/High-Stakes
       â”‚                           â”‚
       â–¼                           â–¼
   Pure Voice              Hybrid + Confirmation
   
   "What's my balance?"    "Book me a flight to Tokyo"
   â†’ Instant answer        â†’ Voice + form checkpoint
   
   
   "Send $20 to Alex"      "Apply for mortgage"
   â†’ Confirm + execute     â†’ Structured form (too complex)
   
   
   "Pay electric bill"     "Configure investment portfolio"
   â†’ Voice command         â†’ Conversation + review step


NOISE LEVEL vs MODALITY

Quiet Environment          Noisy Environment
       â”‚                         â”‚
       â–¼                         â–¼
  Voice Primary            Text/Form Fallback
  
  
USER EXPERTISE vs GUIDANCE

Expert User                Novice User
       â”‚                         â”‚
       â–¼                         â–¼
  Direct Commands          Guided Conversation
  
  "transfer 500 checking   "I need to move money"
   to savings"             â†’ AI asks clarifying questions
        </pre></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">ARCHITECTURE IMPLICATIONS</h2> <p class="mb-3 font-mono">Edge + AI changes backend patterns.</p> <p class="mb-6">Traditional backend expected structured POST data. Post-form backend
        handles ambiguous input, extracts intent, routes to appropriate handler.
        State shifts from "form state" to "intent state."</p> <div class="border-2 border-black"><!--[!--><pre class="bg-black border-2 border-black p-4 overflow-x-auto text-white"><code>// Edge implications of post-form interfaces

// Traditional: Form â†’ Validation â†’ Submit â†’ Backend
app.post("/submit-form", async (req) => {
  const data = validate(req.body);
  return await db.insert(data);
});

// Post-form: Intent â†’ Extract â†’ Validate â†’ Execute
app.post("/intent", async (req) => {
  const { input, modality } = req.body; // voice, text, etc
  
  // Extract structured intent
  const intent = await ai.extract({
    input,
    schema: getIntentSchema(modality)
  });
  
  // Validate extraction
  const valid = validate(intent);
  
  if (!valid.ok) {
    // Ask for clarification (conversation mode)
    return { 
      type: "clarification", 
      message: generateQuestion(valid.missing)
    };
  }
  
  // Execute if confident
  if (intent.confidence > 0.9) {
    return await executeIntent(intent);
  }
  
  // Otherwise checkpoint with form
  return {
    type: "confirm",
    form: generateForm(intent),
    prefilled: true
  };
});

// State management shifts from "form state" to "intent state"
// Validation becomes "extraction confidence"
// Submit becomes "execute when ready"</code></pre><!--]--><!----></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">WHAT ACTUALLY HAPPENS</h2> <div class="space-y-4"><div class="border-2 border-black p-4"><h4 class="font-bold font-mono mb-2">FORMS DON'T DIE</h4> <p class="text-sm">They evolve. Context-aware forms that pre-fill. Progressive
            disclosure that shows relevant fields. Smarter validation that
            accepts natural input. Forms stick around, they just get less
            annoying.</p></div> <div class="border-2 border-black p-4"><h4 class="font-bold font-mono mb-2">VOICE BECOMES VIABLE FOR MORE</h4> <p class="text-sm">Not everything, but way more than now. Balance checks. Simple
            transfers. Bill payments. Booking appointments. Calendar management.
            Any simple, structured task with low stakes.</p></div> <div class="border-2 border-black p-4"><h4 class="font-bold font-mono mb-2">HYBRID DOMINATES</h4> <p class="text-sm">Most interesting workflows become hybrid. Natural language
            collection, structured confirmation. Voice input with visual
            feedback. Conversation with checkpoints. Best of both modalities.</p></div> <div class="border-2 border-black p-4"><h4 class="font-bold font-mono mb-2">INTENT ROUTING IS KEY</h4> <p class="text-sm">The winning architecture: classify intent, route to appropriate
            interface. Simple â†’ voice. Complex â†’ form. Medium â†’ hybrid. The
            interface adapts to the task, not the other way around.</p></div> <div class="border-2 border-black p-4"><h4 class="font-bold font-mono mb-2">MOBILE GOES VOICE-FIRST</h4> <p class="text-sm">Typing on phones sucks. Voice is better for 80% of mobile
            interactions. Desktop stays form-heavy. The modality split follows
            device context, not user preference.</p></div></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">THE WEIRD IMPLICATIONS</h2> <div class="space-y-6"><div><h3 class="text-xl font-bold font-mono mb-3">ACCESSIBILITY INVERTS</h3> <p class="mb-2">Right now: forms are baseline, voice is accessibility feature.</p> <p class="mb-2">Future: voice is baseline, forms are accessibility feature for
            people who can't speak or are in noisy environments.</p> <p>The "accessible" version becomes the structured fallback, not the
            voice interface.</p></div> <div><h3 class="text-xl font-bold font-mono mb-3">UI DESIGN SHIFTS</h3> <p class="mb-2">Current UI design: arrange fields, choose input types, write labels.</p> <p class="mb-2">Post-form UI design: design conversation flows, determine confidence
            thresholds, decide when to show structure.</p> <p>Designers become conversation architects, not form builders.</p></div> <div><h3 class="text-xl font-bold font-mono mb-3">VALIDATION BECOMES CONFIDENCE</h3> <p class="mb-2">Forms have validation rules. Email regex, required fields, min/max
            values.</p> <p class="mb-2">Voice has confidence scores. Did I extract the right intent? Is this
            value plausible? Should I ask for confirmation?</p> <p>Backend validation shifts from "is this valid?" to "am I confident
            enough to proceed?"</p></div> <div><h3 class="text-xl font-bold font-mono mb-3">ERRORS BECOME CLARIFICATIONS</h3> <p class="mb-2">Form error: "Please enter a valid email address."</p> <p class="mb-2">Voice clarification: "I didn't catch your email. Could you spell it
            out?"</p> <p>Errors transform from validation failures to conversation
            continuations.</p></div> <div><h3 class="text-xl font-bold font-mono mb-3">FORMS BECOME TRAINING DATA</h3> <p class="mb-2">When user says "book flight to Tokyo" and edits the extracted
            departure city, that's a training signal.</p> <p class="mb-2">When user switches from voice to form, that's feedback that
            confidence was too low.</p> <p>Every interaction teaches the system when to use which modality.</p></div></div></div> <div><h2 class="text-2xl font-bold font-mono mb-4">IMPLEMENTATION STRATEGY</h2> <ol class="list-decimal ml-6 space-y-4"><li><strong>Start with intent classification</strong> <p class="mt-1 text-sm">Build the router first. Given any input, determine task type and
            required interface. This is the foundation.</p></li> <li><strong>Add voice to simple flows</strong> <p class="mt-1 text-sm">Balance checks, simple transfers, status queries. Low-risk,
            high-frequency. Prove the pattern works.</p></li> <li><strong>Build hybrid for medium complexity</strong> <p class="mt-1 text-sm">Voice input â†’ extraction â†’ form confirmation. Handles the majority
            of workflows. Escape hatch on both ends.</p></li> <li><strong>Keep forms for complex/critical</strong> <p class="mt-1 text-sm">Mortgage applications, legal agreements, complex configurations.
            Some things need explicit structure and review. Don't force voice.</p></li> <li><strong>Measure confidence and adapt</strong> <p class="mt-1 text-sm">Track extraction confidence, user corrections, modality switches.
            Use data to tune when to use which interface. Let users teach the
            system.</p></li></ol></div> <div><h2 class="text-2xl font-bold font-mono mb-4">WHAT THIS MEANS FOR BUILDERS</h2> <ul class="list-disc ml-6 space-y-2"><li><strong>Design for multiple modalities</strong> - Don't assume keyboard
          input. Design for voice, form, and hybrid flows.</li> <li><strong>Intent extraction is infrastructure</strong> - Every app needs
          a layer that maps natural input to structured data.</li> <li><strong>Confidence thresholds matter</strong> - When to auto-execute, when
          to confirm, when to ask for clarification. Tune per use case.</li> <li><strong>Forms are fallbacks, not defaults</strong> - Start with natural
          input. Fall back to structure when needed. Invert the current pattern.</li> <li><strong>Context is everything</strong> - Pre-fill from user history, recent
          activity, location. Make the structured path faster by doing half the work.</li> <li><strong>Accessibility becomes bidirectional</strong> - Both voice and form
          need to be first-class. Neither is the "accessible alternative."</li></ul></div> <div><h2 class="text-2xl font-bold font-mono mb-4">THE BOTTOM LINE</h2> <p class="mb-4">Forms don't disappear. They become one option among many.</p> <p class="mb-4">Simple tasks go full voice. Complex tasks stay structured. Everything in
        between becomes hybridâ€”natural input with structured confirmation.</p> <p class="mb-4">The "internet of forms" becomes the "internet of intents." You express
        what you want however makes senseâ€”voice, typing, clicking. The system
        figures out the structure.</p> <p class="mb-4">Architecturally, this means intent extraction becomes infrastructure.
        Every app needs the ability to parse natural input, extract structured
        data, route to appropriate handlers. That layer doesn't exist widely
        yet. It will.</p> <p>The post-form web isn't formless. It's form-optional. Structure when
        needed, conversation when possible, hybrid when in doubt.</p></div> <div class="border-t-2 border-black pt-6"><h3 class="text-xl font-bold font-mono mb-2">Related patterns</h3> <ul class="list-disc ml-6"><li><a class="underline" href="/trust-broker">Trust Broker: Human-mediated agent communication</a></li> <li><a class="underline" href="/agentic-architecture">Agentic AI Architectures</a></li> <li><a class="underline" href="/workflow-live">Workflow Live: Real-time monitoring</a></li> <li><a class="underline" href="/userdo">UserDO: Per-user state</a></li></ul></div></div></section><!----><!----></main><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_seuxg2 = {
						base: new URL(".", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("./_app/immutable/entry/start.B6XN_71n.js"),
						import("./_app/immutable/entry/app.BC487iTC.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 14],
							data: [{type:"data",data:{user:null,session:null},uses:{}},null],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
